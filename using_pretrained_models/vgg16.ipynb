{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pre-trained VGG16 model\n",
    "\n",
    "- [code example from fchollet](https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069)\n",
    "- [related keras.io blog post](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "- [pixel-wise classification in keras](https://github.com/fchollet/keras/issues/1169)\n",
    "\n",
    "The top layers of VGG16 are Flatten, Dense (fully-connected 1), Dense (fully-connected 2), Dense (prediction).\n",
    "\n",
    "## To-do\n",
    "\n",
    "1. ~~Use a generator when fitting and predicting.~~\n",
    "2. Fix bug where batch size has to divide evenly into number of samples.\n",
    "    - Is this in fact a bug? Or expected behavior.\n",
    "3. Use open-cv instead of scipy to resize images. Open-cv is faster.\n",
    "    - Original data is int64. Open-cv doesn't like that, but it likes float64. Normalize to range [0, 1], which will give a float (probably float64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import Iterator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras\", keras.__version__)\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"OpenCV\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'data_path': '/data/metasearch-anatomical-brainmask-slices.h5',\n",
    "          'slice_shape': (224, 224),\n",
    "          'nb_train_start': 0,\n",
    "          'nb_train_samples': 1000,\n",
    "          'nb_test_start': 100000,\n",
    "          'nb_test_samples': 1000,\n",
    "          'epochs': 1,\n",
    "          'batch_size': 25,\n",
    "          'train_features_path': '/data/bottleneck_features_train.npy',\n",
    "          'test_features_path': '/data/bottleneck_features_test.npy',\n",
    "          'top_model_weights_path': '/data/top-model-weight.h5',\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------\n",
    "# Data processing functions\n",
    "#--------------------------\n",
    "\n",
    "def _normalize(arr):\n",
    "    \"\"\"Return array normalized to range [0, 1].\"\"\"\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "\n",
    "def _normalize_and_resize_2d(arr2d, new_shape):\n",
    "    \"\"\"Return 2D array normalized to range [0, 1] and resized to `new_shape`.\"\"\"\n",
    "    return cv2.resize(_normalize(arr2d), new_shape, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # # Scipy resizing changes data range when using float64. OpenCV does not.\n",
    "    # # OpenCV does not want to resize an image with int64 (why?), but this does\n",
    "    # # concern us because normalizing returns float64.\n",
    "    # # See https://github.com/scipy/scipy/issues/4458#issuecomment-269067103.\n",
    "    #\n",
    "    # return scipy.misc.imresize(arr2d, new_shape, interp='nearest')\n",
    "\n",
    "\n",
    "def _process_3d(arr3d, new_shape):\n",
    "    \"\"\"Return 3D array that is normalized by slice to range [0, 1] and resized to\n",
    "    `new_shape` on dims 1 and 2.\n",
    "    \"\"\"\n",
    "    n_slices = arr3d.shape[0]\n",
    "    processed_arr = np.zeros((n_slices, *new_shape))\n",
    "    for idx in range(n_slices):\n",
    "        processed_arr[idx, :, :] = _normalize_and_resize_2d(arr3d[idx, :, :],\n",
    "                                                            new_shape)\n",
    "    return processed_arr\n",
    "\n",
    "\n",
    "def _process_2d(arr2d, new_shape):\n",
    "    \"\"\"Return 2D array that is normalized to range [0, 1] and resized to `new_shape`.\n",
    "    \"\"\"\n",
    "    return _normalize_and_resize_2d(arr2d, new_shape)\n",
    "\n",
    "\n",
    "def _process_shared(arr, new_shape):\n",
    "    \"\"\"Return processed batch of data (processing shared by X and y data).\n",
    "    Array can be 2D or 3D.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return _process_3d(arr, new_shape)\n",
    "    except IndexError:\n",
    "        return _process_2d(arr, new_shape)\n",
    "\n",
    "\n",
    "def _add_color_channels(arr):\n",
    "    \"\"\"Return array with values copied to mimic RGB color channels. Color channels\n",
    "    are in the *last* axis.\n",
    "    \"\"\"\n",
    "    arr.resize((*arr.shape, 1))\n",
    "    return np.tile(arr, 3)\n",
    "\n",
    "\n",
    "def process_X_data(arr, new_shape=params['slice_shape']):\n",
    "    \"\"\"Return processed batch of data. Resizes slices to `new_shape`\n",
    "    and copies values to mimic RGB color channels.\n",
    "    \"\"\"\n",
    "    arr = _process_shared(arr, new_shape=new_shape)\n",
    "    return _add_color_channels(arr)\n",
    "\n",
    "\n",
    "def process_y_data(arr, new_shape=params['slice_shape']):\n",
    "    \"\"\"Return processed batch of data. Resizes slices to `new_shape`.\"\"\"\n",
    "    return _process_shared(arr, new_shape=new_shape)\n",
    "\n",
    "\n",
    "class SliceIterator(keras.preprocessing.image.Iterator):\n",
    "    \"\"\"Iterator yielding batches of data from 3D array of slices.\n",
    "    \n",
    "    Based on keras's NumpyArrayIterator:\n",
    "    https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py#L735-L823\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y=None, batch_size=32, shuffle=False, seed=None):\n",
    "        if y is not None and len(X) != len(y):\n",
    "            raise ValueError('X and y should have the same length.')\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        super(SliceIterator, self).__init__(X.shape[0], batch_size, shuffle, seed)\n",
    "\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x (???)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The next batch. If `y` is not None, return tuple of X and y batches. Otherwise,\n",
    "        return X batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "\n",
    "        # # The code below is faster\n",
    "        # upper_index = current_index + current_batch_size\n",
    "        # self.X[current_index:upper_index], self.y[current_index:upper_index]\n",
    "\n",
    "        if self.y is None:\n",
    "            return self.X[index_array]\n",
    "\n",
    "        return self.X[index_array], self.y[index_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = HDF5Matrix(params['data_path'], '/anatomical/axial', \n",
    "                     start=params['nb_train_start'], \n",
    "                     end=params['nb_train_start']+params['nb_train_samples'],\n",
    "                     normalizer=process_X_data)\n",
    "\n",
    "y_train = HDF5Matrix(params['data_path'], '/brainmask/axial',\n",
    "                     start=params['nb_train_start'],\n",
    "                     end=params['nb_train_start']+params['nb_train_samples'],\n",
    "                     normalizer=process_y_data)\n",
    "\n",
    "X_test = HDF5Matrix(params['data_path'], '/anatomical/axial',\n",
    "                    start=params['nb_test_start'],\n",
    "                    end=params['nb_test_start']+params['nb_test_samples'],\n",
    "                    normalizer=process_X_data)\n",
    "\n",
    "y_test = HDF5Matrix(params['data_path'], '/brainmask/axial',\n",
    "                    start=params['nb_test_start'],\n",
    "                    end=params['nb_test_start']+params['nb_test_samples'],\n",
    "                    normalizer=process_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Time taken to load and preprocess a single slice and a batch.\")\n",
    "print(\"batch size:\", params['batch_size'], \"slices\")\n",
    "%timeit X_train[0]\n",
    "%timeit X_train[:params['batch_size']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_bottleneck_features():\n",
    "    model = keras.applications.VGG16(include_top=False, weights='imagenet',\n",
    "                                     input_shape=params['slice_shape']+(3,))\n",
    "\n",
    "    # Instantiate generators of batches.\n",
    "    generator_train_X = SliceIterator(X_train, batch_size=params['batch_size'])\n",
    "    generator_test_X = SliceIterator(X_test, batch_size=params['batch_size'])\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator_train_X, params['nb_train_samples'] // params['batch_size'],\n",
    "        verbose=1)\n",
    "\n",
    "    np.save(params['train_features_path'], bottleneck_features_train)\n",
    "\n",
    "\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator_test_X, params['nb_train_samples'] // params['batch_size'],\n",
    "        verbose=1)\n",
    "\n",
    "    np.save(params['test_features_path'], bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    X_train_features = np.load(params['train_features_path'])\n",
    "    X_test_features = np.load(params['test_features_path'])\n",
    "    print(\"Train shape:\", X_train_features.shape)\n",
    "    print(\"Test shape:\", X_test_features.shape)\n",
    "\n",
    "    train_generator = SliceIterator(X_train_features, y_train, params['batch_size'])\n",
    "    test_generator = SliceIterator(X_test_features, y_test, params['batch_size'])\n",
    "\n",
    "    # https://github.com/fchollet/keras/issues/1169#issuecomment-162260972\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=X_train_features.shape[1:]))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Classification\n",
    "    np.multiply(*params['slice_shape'])\n",
    "    \n",
    "    model.add(Dense(np.multiply(*params['slice_shape']), activation='sigmoid'))\n",
    "    model.add(Reshape(params['slice_shape']))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    steps = params['nb_train_samples'] // params['batch_size']\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps, epochs=3,\n",
    "                        validation_data=test_generator, validation_steps=steps,\n",
    "                        verbose=1)\n",
    "\n",
    "    model.save_weights(params['top_model_weights_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train the joined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_models():\n",
    "    # https://github.com/fchollet/keras/issues/4040#issuecomment-253309615\n",
    "    \n",
    "    initial_model = keras.applications.VGG16(include_top=False, weights='imagenet',\n",
    "                                             input_shape=params['slice_shape']+(3,))\n",
    "\n",
    "    x = Flatten()(initial_model.output)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # Classification\n",
    "    np.multiply(*params['slice_shape'])\n",
    "    x = Dense(np.multiply(*params['slice_shape']), activation='sigmoid')(x)\n",
    "    preds = Reshape(params['slice_shape'])(x)\n",
    "    \n",
    "    # Combine models.\n",
    "    model = Model(initial_model.input, preds)\n",
    "\n",
    "    # Freeze the convolutional part of the model.\n",
    "    for layer in model.layers[:19]:  \n",
    "        layer.trainable = False\n",
    "\n",
    "    model.load_weights(params['top_model_weights_path'], by_name=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = join_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_train = SliceIterator(X_train, y_train, batch_size=params['batch_size'])\n",
    "generator_test = SliceIterator(X_test, y_test, batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator_train,\n",
    "    steps_per_epoch=params['nb_train_samples'] // params['batch_size'],\n",
    "    epochs=params['epochs'],\n",
    "    validation_data=generator_test,\n",
    "    validation_steps=params['nb_test_samples'] // params['batch_size'],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"/data/vgg16-combined-model-20170630-first-try.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(X_test[49:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0].T, cmap='gray', origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_test[0].T, cmap='gray', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/aurora95/Keras-FCN/blob/master/utils/BilinearUpSampling.py\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Layer, InputSpec\n",
    "import tensorflow as tf\n",
    "\n",
    "# How is this different from keras.layers.UpSampling2D?\n",
    "\n",
    "def resize_images_bilinear(X, height_factor=1, width_factor=1, target_height=None, target_width=None, data_format='default'):\n",
    "    '''Resizes the images contained in a 4D tensor of shape\n",
    "    - [batch, channels, height, width] (for 'channels_first' data_format)\n",
    "    - [batch, height, width, channels] (for 'channels_last' data_format)\n",
    "    by a factor of (height_factor, width_factor). Both factors should be\n",
    "    positive integers.\n",
    "    '''\n",
    "    if data_format == 'default':\n",
    "        data_format = K.image_data_format()\n",
    "    if data_format == 'channels_first':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[2:]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = permute_dimensions(X, [0, 2, 3, 1])\n",
    "        X = tf.image.resize_bilinear(X, new_shape)\n",
    "        X = permute_dimensions(X, [0, 3, 1, 2])\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, None, target_height, target_width))\n",
    "        else:\n",
    "            X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n",
    "        return X\n",
    "    elif data_format == 'channels_last':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[1:3]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = tf.image.resize_bilinear(X, new_shape)\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, target_height, target_width, None))\n",
    "        else:\n",
    "            X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n",
    "        return X\n",
    "    else:\n",
    "        raise Exception('Invalid data_format: ' + data_format)\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(1, 1), target_size=None, data_format='default', **kwargs):\n",
    "        if data_format == 'default':\n",
    "            data_format = K.image_data_format()\n",
    "        self.size = tuple(size)\n",
    "        if target_size is not None:\n",
    "            self.target_size = tuple(target_size)\n",
    "        else:\n",
    "            self.target_size = None\n",
    "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {tf, th}'\n",
    "        self.data_format = data_format\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            width = int(self.size[0] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[3] if input_shape[3] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    width,\n",
    "                    height)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            width = int(self.size[0] * input_shape[1] if input_shape[1] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    width,\n",
    "                    height,\n",
    "                    input_shape[3])\n",
    "        else:\n",
    "            raise Exception('Invalid data_format: ' + self.data_format)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.target_size is not None:\n",
    "            return resize_images_bilinear(x, target_height=self.target_size[0], target_width=self.target_size[1], data_format=self.data_format)\n",
    "        else:\n",
    "            return resize_images_bilinear(x, height_factor=self.size[0], width_factor=self.size[1], data_format=self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'size': self.size, 'target_size': self.target_size}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/fchollet/keras/issues/4465#issuecomment-262229784\n",
    "# https://github.com/aurora95/Keras-FCN/blob/master/models.py#L23\n",
    "# https://github.com/aurora95/Keras-FCN/blob/master/models.py#L82\n",
    "\n",
    "n_classes = 2\n",
    "weight_decay = 0.\n",
    "\n",
    "# Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False,\n",
    "                         input_shape=(224, 224, 3))\n",
    "model_vgg16_conv.trainable = False\n",
    "\n",
    "slice_input = Input(shape=(224, 224, 3), name='slice_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(slice_input)\n",
    "\n",
    "x = Dropout(0.5)(output_vgg16_conv)\n",
    "\n",
    "# Classifying layer.\n",
    "x = Convolution2D(n_classes, (1, 1), kernel_initializer='he_normal', \n",
    "                  activation='linear', padding='valid', strides=(1, 1), \n",
    "                  kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "# x = UpSampling2D(size=(32, 32))(x)\n",
    "x = BilinearUpSampling2D(size=(32, 32))(x)\n",
    "\n",
    "model = Model(slice_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta', loss='binary_crossentropy',\n",
    "              metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_slice = 50\n",
    "\n",
    "out = model.predict(X_train[predict_slice])\n",
    "print(\"Original:\", out.shape)\n",
    "out = out.squeeze()\n",
    "print(\"Reshaped:\", out.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "img_labels = np.argmax(out, axis=2)\n",
    "\n",
    "ax.imshow(X_train[predict_slice].squeeze()[:, :, 1].T, cmap='gray')\n",
    "ax.imshow(np.ma.masked_where(img_labels<0.5, img_labels), alpha=.7,\n",
    "          cmap='autumn', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('/data/metasearch-anatomical-brainmask-slices.h5', 'r') as fp:\n",
    "    X_train = fp['/anatomical/axial'][:100]\n",
    "    y_train = fp['/anatomical/axial'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_arrays_from_hdf5(path, start=0, end=None, view='axial', normalizer=None):\n",
    "    import h5py\n",
    "\n",
    "    X_dataset = \"/anatomical/{}\".format(view)\n",
    "    y_dataset = \"/brainmask/{}\".format(view)\n",
    "\n",
    "    with h5py.File(path, 'r') as fp:\n",
    "        for i in range(start, end):\n",
    "            X = fp[X_dataset][i]\n",
    "            y = fp[y_dataset][i]\n",
    "            \n",
    "            if normalizer is not None:\n",
    "                X = normalizer(X)\n",
    "                y = normalizer(y)\n",
    "            \n",
    "            yield (X, y)\n",
    "\n",
    "data_path = '/data/metasearch-anatomical-brainmask-slices.h5'\n",
    "\n",
    "generator = generate_arrays_from_hdf5(data_path, end=100, normalizer=process_slice)\n",
    "\n",
    "model.fit_generator(generator, steps_per_epoch=10, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "weight_decay = 0.\n",
    "\n",
    "model_vgg16_conv = VGG16(include_top=True, weights='imagenet')\n",
    "# model_vgg16_conv.trainable = False\n",
    "\n",
    "input_ = Input(shape=(256, 256, 3), name='slice_input')\n",
    "output_vgg16_conv = model_vgg16_conv(input_)\n",
    "\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "# x = Convolution2D(4096, 7, 7, activation='relu', border_mode='same', name='fc1', W_regularizer=l2(weight_decay))(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "# Classifying layer.\n",
    "x = Convolution2D(2, 1, 1, init='he_normal', activation='linear', border_mode='valid', subsample=(1, 1), W_regularizer=l2(weight_decay))(x)\n",
    "x = BilinearUpSampling2D(size=(32, 32))(x)\n",
    "model = Model(input_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top=True, weights='imagenet')\n",
    "model.trainable = False\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = model.predict(X_train[10])\n",
    "print(np.argmax(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one_slice = Input(shape=(None, 256, 256, 3))\n",
    "cnn = VGG16(include_top=True, weights='imagenet')\n",
    "cnn.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dense(128, activation='relu')(cnn)\n",
    "outputs = Dense(1000)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "473px",
    "left": "1px",
    "right": "20px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
