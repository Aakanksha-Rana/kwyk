{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement highres3dnet\n",
    "\n",
    "Paper: https://arxiv.org/abs/1707.01992\n",
    "\n",
    "Preprocessing steps\n",
    "---\n",
    "- Anatomical\n",
    "    1. Load.\n",
    "    1. Squeeze data array.\n",
    "    1. Check for 3 dimensions.\n",
    "    1. Add one color channel.\n",
    "- Labels\n",
    "    1. Load.\n",
    "    1. Squeeze data array.\n",
    "    1. Check for 3 dimensions.\n",
    "    1. One-hot encode.\n",
    "   \n",
    "Loading steps\n",
    "---\n",
    "1. Load anatomical and labels.\n",
    "1. Get blocks for each array.\n",
    "1. Feed those blocks into the model in batches.\n",
    "\n",
    "Questions\n",
    "---\n",
    "1. Should we impose a restriction, where batch size must be evenly divisible by number of blocks (viewpoints) that are in a volume? Probably.\n",
    "\n",
    "Todo\n",
    "---\n",
    "- Look into [`keras.utils.multi_gpu_model`](https://keras.io/utils/#multi_gpu_model) to train on multiple GPUs. This is only available for the TensorFlow backend.\n",
    "- Learn about one-hot encoding / decoding. Encode the array of labels with `K.one_hot()`. Decode the predictions with `K.argmax()`. `K.one_hot()` simply calls `tf.one_hot()`, so this would restrict us to the TensorFlow backend, which is fine for now.\n",
    "\n",
    "\n",
    "Notes\n",
    "---\n",
    "- NiftyNet trains on a sliding window over the 3D data. This should have that ability to lower GPU memory requirements.\n",
    "\n",
    "Future considerations\n",
    "---\n",
    "- Modify `highres3dnet` to use ResNeXt architechture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from warnings import warn\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from highres3dnet import dice_loss, HighRes3DNet\n",
    "\n",
    "logger = logging.getLogger(name=__name__)\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-4\n",
    "CSV_FILEPATH = \"/om/user/jakubk/nobrainer-code/niftynet_to_keras/t1_brainmask.csv\"\n",
    "WINDOW_SHAPE = (64, 64, 64)\n",
    "NUM_CHANNELS = 1\n",
    "INPUT_SHAPE = (*WINDOW_SHAPE, NUM_CHANNELS)\n",
    "TARGET_DTYPE = 'uint8'\n",
    "TENSORBOARD_BASE_DIR = \"/om/user/jakubk/nobrainer-code/niftynet_to_keras/models\"\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_timestamp():\n",
    "    import datetime\n",
    "    return str(datetime.datetime.now()).split('.')[0].replace(' ', '_')\n",
    "\n",
    "\n",
    "def get_tensorboard_dir(base_dir=None):\n",
    "    if base_dir is None:\n",
    "        base_dir = os.getcwd()\n",
    "    window = \"_\".join(str(ii) for ii in WINDOW_SHAPE)\n",
    "    rel_dir = (\n",
    "        \"highres3dnet-{num_classes}_classes-{lr}_lr-{batch}_batch-{window}_window-{ts}\"\n",
    "    ).format(\n",
    "        num_classes=NUM_CLASSES, lr=LEARNING_RATE, batch=BATCH_SIZE, \n",
    "        window=window, ts=_get_timestamp())\n",
    "    return os.path.join(base_dir, rel_dir, 'logs')\n",
    "\n",
    "\n",
    "def load_volume(filepath, return_affine=False, c_contiguous=True, dtype=None):\n",
    "    \"\"\"Return data given filepath to volume. Optionally return affine array.\n",
    "\n",
    "    Making the data array contiguous takes more time during loading, but this\n",
    "    ultimately saves time when viewing blocks of data with `skimage`.\n",
    "    \"\"\"\n",
    "    img = nib.load(filepath)\n",
    "    data = np.asarray(img.dataobj)\n",
    "    if dtype is not None:\n",
    "        data = data.astype(dtype)\n",
    "    img.uncache()\n",
    "    if c_contiguous:\n",
    "        data = np.ascontiguousarray(data)\n",
    "    if return_affine:\n",
    "        return data, img.affine\n",
    "    return data\n",
    "\n",
    "\n",
    "def one_hot(a, **kwargs):\n",
    "    \"\"\"Return one-hot array of N-D array `a`.\"\"\"\n",
    "    # https://stackoverflow.com/a/37323404/5666087\n",
    "    n_values = np.max(a) + 1\n",
    "    return np.eye(n_values, **kwargs)[a]\n",
    "\n",
    "\n",
    "def _preprocess_data(data):\n",
    "    data = view_as_blocks(data, WINDOW_SHAPE).reshape(-1, *WINDOW_SHAPE)\n",
    "    return data[Ellipsis, np.newaxis]\n",
    "\n",
    "\n",
    "def _preprocess_target(target):\n",
    "    target = one_hot(target, dtype=TARGET_DTYPE)\n",
    "    new_shape = (*WINDOW_SHAPE, NUM_CLASSES)\n",
    "    return view_as_blocks(target, new_shape).reshape(-1, *new_shape)\n",
    "\n",
    "\n",
    "def view_as_blocks(arr_in, block_shape):\n",
    "    \"\"\"Block view of the input n-dimensional array (using re-striding).\n",
    "    Blocks are non-overlapping views of the input array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr_in : ndarray\n",
    "        N-d input array.\n",
    "    block_shape : tuple\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Copied from `skimage.util.view_as_blocks` to avoid having to install the\n",
    "    entire package + dependencies.\n",
    "    \"\"\"\n",
    "    if not isinstance(block_shape, tuple):\n",
    "        raise TypeError('block needs to be a tuple')\n",
    "\n",
    "    block_shape = np.array(block_shape)\n",
    "    if (block_shape <= 0).any():\n",
    "        raise ValueError(\"'block_shape' elements must be strictly positive\")\n",
    "\n",
    "    if block_shape.size != arr_in.ndim:\n",
    "        raise ValueError(\"'block_shape' must have the same length \"\n",
    "                         \"as 'arr_in.shape'\")\n",
    "\n",
    "    arr_shape = np.array(arr_in.shape)\n",
    "    if (arr_shape % block_shape).sum() != 0:\n",
    "        raise ValueError(\"'block_shape' is not compatible with 'arr_in'\")\n",
    "\n",
    "    # -- restride the array to build the block view\n",
    "\n",
    "    if not arr_in.flags.contiguous:\n",
    "        warn(RuntimeWarning(\"Cannot provide views on a non-contiguous input \"\n",
    "                            \"array without copying.\"))\n",
    "\n",
    "    arr_in = np.ascontiguousarray(arr_in)\n",
    "\n",
    "    new_shape = tuple(arr_shape // block_shape) + tuple(block_shape)\n",
    "    new_strides = tuple(arr_in.strides * block_shape) + arr_in.strides\n",
    "\n",
    "    arr_out = as_strided(arr_in, shape=new_shape, strides=new_strides)\n",
    "\n",
    "    return arr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_input = pd.read_csv(CSV_FILEPATH)\n",
    "\n",
    "model = HighRes3DNet(n_classes=NUM_CLASSES, input_shape=INPUT_SHAPE)\n",
    "\n",
    "# Use multiple GPUs.\n",
    "# gpu_ids = [int(ss) for ss in os.environ['CUDA_VISIBLE_DEVICES'].split(',')]\n",
    "# model = keras.utils.multi_gpu_model(model, gpus=gpu_ids)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(adam, dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/5935#issuecomment-289041967\n",
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        import resource\n",
    "        # max resident set size\n",
    "        usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "        usage = usage * resource.getpagesize() / 1000000.0\n",
    "        print(\"Usage: {:0.0f} Mb\".format(usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_tensorboard_dir = get_tensorboard_dir(base_dir=TENSORBOARD_BASE_DIR)\n",
    "\n",
    "print(\"++ Saving Tensorboard information to\\n{}\".format(_tensorboard_dir))\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=_tensorboard_dir,\n",
    "        write_graph=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(_tensorboard_dir, \"..\", \"model-{epoch:02d}.h5\"),\n",
    "        period=50,\n",
    "    ),\n",
    "    tf.keras.callbacks.CSVLogger(\n",
    "        filename=os.path.join(_tensorboard_dir, \"..\", \"training.log\"),\n",
    "        append=True,\n",
    "    ),\n",
    "    MemoryCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, these_files in df_input.iterrows():\n",
    "    \n",
    "    data = load_volume(these_files['t1'])\n",
    "    data = _preprocess_data(data)\n",
    "    \n",
    "    target = load_volume(these_files['brainmask'], dtype=TARGET_DTYPE)\n",
    "    target = _preprocess_target(target)\n",
    "    \n",
    "    model.fit(\n",
    "        x=data,\n",
    "        y=target,\n",
    "        epochs=1,\n",
    "        batch_size=8,\n",
    "        verbose=1,\n",
    "        # callbacks=callbacks\n",
    "    )\n",
    "    if index > 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from warnings import warn\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from highres3dnet import dice_loss, HighRes3DNet\n",
    "\n",
    "logger = logging.getLogger(name=__name__)\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.001\n",
    "CSV_FILEPATH = \"/om/user/jakubk/nobrainer-code/niftynet_to_keras/t1_brainmask.csv\"\n",
    "WINDOW_SHAPE = (128, 128, 128)\n",
    "NUM_CHANNELS = 1\n",
    "INPUT_SHAPE = (*WINDOW_SHAPE, NUM_CHANNELS)\n",
    "TARGET_DTYPE = 'uint8'\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat = load_volume(\n",
    "    '/om2/user/jakubk/mindboggle-101/T1/__om2__user__jakubk__mindboggle-101__FreeSurfer_output__HLN-12-5__mri__T1.nii.gz'\n",
    ")\n",
    "anat = _preprocess_data(anat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(anat[4, :, 100, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    'model_nobrainer/model-00.h5', custom_objects={'dice_loss': dice_loss}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(anat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = prediction[4, :, 100, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(view, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(view[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
